{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584ff92-e913-4078-af68-b792b96f38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Graphic Settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\">>> The libraries are successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcbd38-2731-45a4-89e4-4af5392429ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import our dataset. If an error occurs, an alert is displayed.\n",
    "try:\n",
    "    df = pd.read_csv('data.csv', sep=';')\n",
    "    print(f\">>> Veri Seti Yüklendi. Boyut: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"HATA: 'data.csv' dosyası bulunamadı.Tekrar deneyin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61da81-aea3-44e8-ac4c-6f08fb18ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf79f4-f484-4c46-afb0-9fb479baccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fccaa-6796-4591-a5e8-1e898693a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adaee4-9f2e-4584-98b9-3d36c131fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking total null values(missing values)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e3f14-ae34-442a-99c7-c54a27eaa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pie = df['Target'].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PIE CHART\n",
    "ax1.pie(\n",
    "    data_pie,\n",
    "    autopct=\"%.2f%%\",\n",
    "    labels=[\"Dropout\", \"Enrolled\", \"Graduate\"],\n",
    "    colors=sns.color_palette('Set2') \n",
    ")\n",
    "ax1.set_title('Percentage of students')\n",
    "\n",
    "# BAR CHART\n",
    "sns.barplot(\n",
    "    x=[\"Dropout\", \"Enrolled\", \"Graduate\"],\n",
    "    y=data_pie.values,\n",
    "    palette=\"Set2\",                 \n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('Target Categories')\n",
    "ax2.set_ylabel('Number of students')\n",
    "ax2.set_title('Total number of students')\n",
    "\n",
    "# LABELS\n",
    "for i, value in enumerate(data_pie.values):\n",
    "    ax2.text(i, value, value, ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf4de1-0120-452a-9819-0014b025be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We derive additional features to increase the model’s predictive capabilities.\n",
    "\n",
    "print(\">>> Feature Engineering Process\")\n",
    "\n",
    "# A) Rate of Passing Lesson (Approved / Enrolled)\n",
    "df['App_Rate_1st'] = df['Curricular units 1st sem (approved)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "df['App_Rate_2nd'] = df['Curricular units 2nd sem (approved)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "\n",
    "# B) Average Grades\n",
    "df['Grade_Avg'] = (df['Curricular units 1st sem (grade)'] + df['Curricular units 2nd sem (grade)']) / 2\n",
    "\n",
    "# C) Change of the performance(Second Term Grade-First Term Grade)\n",
    "df['Grade_Change'] = df['Curricular units 2nd sem (grade)'] - df['Curricular units 1st sem (grade)']\n",
    "\n",
    "# D) Economic Pressure \n",
    "df['Eco_Stress'] = df['Unemployment rate'] * df['Inflation rate']\n",
    "\n",
    "print(f\">>> To increase performance our model new features added. Current Column Number: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f7f74-25da-4879-ac0f-2f0dd82f54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Data Preprocessing Steps!!!\")\n",
    "\n",
    "# 1. Target Variable Transformation: Converting to Dropout vs Not Dropout\n",
    "df['Target_Binary'] = df['Target'].apply(lambda x: 'Dropout' if x == 'Dropout' else 'Not Dropout')\n",
    "\n",
    "X = df.drop(['Target', 'Target_Binary'], axis=1)\n",
    "y = df['Target_Binary']\n",
    "\n",
    "# 3. Implementation of Label Encoding (Dropout:0 and Not Dropout:1)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\">>> Encoding: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# 4. Splitting Dataset (%80 Train - %20 Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# 5. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\">>> Data has been succesfully splitted and scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec59e70-c7fe-4123-85e9-5bec5fcd3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e174e-96f2-4062-935e-757125e0b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41e5ea-fcc0-4e01-b6d1-36fe15987b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New target distribution visualization\n",
    "\n",
    "target_counts = df['Target_Binary'].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "colors = sns.color_palette(\"Set2\")\n",
    "\n",
    "# PIE CHART\n",
    "ax1.pie(\n",
    "    target_counts.values,\n",
    "    labels=target_counts.index,\n",
    "    autopct=\"%.2f%%\",\n",
    "    startangle=90,\n",
    "    colors=colors\n",
    ")\n",
    "ax1.set_title(\"Target Distribution With Percentages\")\n",
    "\n",
    "# BAR CHART\n",
    "sns.barplot(\n",
    "    x=target_counts.index,\n",
    "    y=target_counts.values,\n",
    "    palette=colors,\n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Target Distribution\")\n",
    "ax2.set_xlabel(\"Target Class\")\n",
    "ax2.set_ylabel(\"Number of Students\")\n",
    "\n",
    "for i, value in enumerate(target_counts.values):\n",
    "    ax2.text(i, value, value, ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d3c7b-c36b-4b67-a7b9-825307b8612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Baseline Model (Dummy) is training...\")\n",
    "\n",
    "# Strategy 'stratified': randomly assigns labels according to the class distribution in the training set.\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_clf.fit(X_train_scaled, y_train)\n",
    "dummy_pred = dummy_clf.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Baseline Accuracy: %{accuracy_score(y_test, dummy_pred)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bba45-d3f2-4488-a51d-1027a9e141c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Initiating Hyperparameter Tuning for the Random Forest model using GridSearchCV...\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Search space of parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# 3-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"\\n>>> Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b781f-5e01-46b8-b1ff-aacc8fdb8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Voting Classifier (RF + HGB + GB) ...\")\n",
    "\n",
    "# GradientBoosting\n",
    "hgb_clf = HistGradientBoostingClassifier(learning_rate=0.1, max_iter=200, random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Voting: Tuned Random Forest + HGB + GB\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('hgb', hgb_clf), ('gb', gb_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "print(\">>> Voting Classifier training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec9525-0068-4377-81b3-38d2842d0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Evaluation is being performed on the test set...\")\n",
    "\n",
    "test_pred = voting_clf.predict(X_test_scaled)\n",
    "test_probs = voting_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "# Metrics\n",
    "print(f\"\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "print(f\" TEST ACCURACY: %{accuracy_score(y_test, test_pred)*100:.2f}\")\n",
    "print(f\" TEST F1-SCORE: %{f1_score(y_test, test_pred, average='weighted')*100:.2f}\")\n",
    "print(f\"\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "print(classification_report(y_test, test_pred, target_names=le.classes_))\n",
    "\n",
    "# Picture1: Confusion Matrix \n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Gerçek Durum')\n",
    "plt.xlabel('Tahmin Edilen Durum')\n",
    "\n",
    "# Picture2: ROC Curve \n",
    "plt.subplot(1, 2, 2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Picture3: Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X.columns)\n",
    "importances.nlargest(15).sort_values(ascending=True).plot(kind='barh', color='#2ecc71')\n",
    "plt.title('Feature Importance (Tuned Random Forest)')\n",
    "plt.xlabel('Önem Derecesi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673f453-02e4-4280-90c8-71aa5aa67235",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_rf.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=feature_importances, y=X.columns)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9bf7d-d194-48c3-8628-a9d584ceaf54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
